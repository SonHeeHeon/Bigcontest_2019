{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 패키지 설치(keras 이용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.random import seed\n",
    "import tensorflow as tf\n",
    "from tensorflow import set_random_seed\n",
    "import keras\n",
    "from keras import models, layers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 신경망 내에서 auc_roc로 측정하기 위해 만든 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc_roc(y_true, y_pred):\n",
    "    # any tensorflow metric\n",
    "    value, update_op = tf.contrib.metrics.streaming_auc(y_pred, y_true)\n",
    "\n",
    "    # find all variables created for this metric\n",
    "    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n",
    "\n",
    "    # Add metric variables to GLOBAL_VARIABLES collection.\n",
    "    # They will be initialized for new session.\n",
    "    for v in metric_vars:\n",
    "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
    "\n",
    "    # force to update metric values\n",
    "    with tf.control_dependencies([update_op]):\n",
    "        value = tf.identity(value)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 각 은닉층의 뉴런 갯수 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nh_l = [300,250, 200, 150, 128, 128] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 은닉층 : 6층 / activation function : relu / learning rate=0.008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_network():\n",
    "    network = models.Sequential()\n",
    "    network.add(layers.Dense(Nh_l[0], activation='relu', input_shape=(len(list(train_x)),)))\n",
    "    network.add(layers.Dense(Nh_l[1]))\n",
    "    network.add(BatchNormalization()) # 표준화를 해주어 gradient vanishing문제를 해결\n",
    "    network.add(layers.Activation('relu'))\n",
    "    network.add(Dropout(0.5)) # 노드를 랜덤으로 없애서 과적합을 없앰 \n",
    "    network.add(layers.Dense(Nh_l[2]))\n",
    "    network.add(layers.Activation('relu'))\n",
    "    network.add(layers.Dense(Nh_l[3]))\n",
    "    network.add(BatchNormalization()) \n",
    "    network.add(layers.Activation('relu'))\n",
    "    network.add(Dropout(0.6))\n",
    "    network.add(layers.Dense(Nh_l[4]))\n",
    "    network.add(BatchNormalization()) \n",
    "    network.add(layers.Activation('relu'))\n",
    "    network.add(layers.Dense(Nh_l[5]))\n",
    "    network.add(layers.Activation('relu'))\n",
    "    network.add(Dropout(0.6)) \n",
    "    network.add(layers.Dense(Nh_l[5]))\n",
    "    network.add(BatchNormalization())  \n",
    "    network.add(layers.Activation('relu'))\n",
    "    network.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile neural network\n",
    "    network.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.008, beta_1=0.9, beta_2=0.999),metrics=[auc_roc])\n",
    "    # Return compiled network+\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 같은 kfold 데이터를 이용하기 위해 R에서 데이터를 가져와서 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(1)\n",
    "set_random_seed(1)\n",
    "tf.set_random_seed(1)\n",
    "auc_score=[]\n",
    "for i in range(1,6) :\n",
    "    train_d=pd.read_csv('C:/Desktop/Son/공모전/빅콘 2019/최종 데이터 및 코드/train_'+str(i)+'.csv',engine = 'python')\n",
    "    valid_d = pd.read_csv(\"C:/Desktop/Son/공모전/빅콘 2019/최종 데이터 및 코드/valid_\"+str(i)+\".csv\",engine='python')\n",
    "    train_y=train_d['dly']\n",
    "    train_x=train_d.drop(['dly','delay_time'],axis=1)\n",
    "    valid_y=valid_d['dly']\n",
    "    valid_x=valid_d.drop(['dly','delay_time'],axis=1)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True) # early stopping이 되기전 최적의 모델을 저장\n",
    "    my_callbacks = EarlyStopping(monitor='val_loss', patience=25, verbose=2, mode='min') # 과적합을 피하기 위해 early stopping 지정\n",
    "    neural_network = KerasClassifier(build_fn=create_network, batch_size=800, epochs=50, verbose=2,validation_data=(valid_x, valid_y),callbacks=[my_callbacks,mc]) # early stopping\n",
    "    nnet=neural_network.fit(train_x, train_y)\n",
    "    ynew = neural_network.predict_proba(valid_x)\n",
    "    real_y=np.array(valid_y)\n",
    "    pred_y=np.array(pd.DataFrame(ynew).loc[:,1])\n",
    "    auc_score.append(roc_auc_score(real_y, pred_y))\n",
    "    valid_1=pd.DataFrame(ynew)\n",
    "    valid_1.to_csv(\"valid_\"+i+\".csv\",mode='w')\n",
    "print(auc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed(1)\n",
    "set_random_seed(1)\n",
    "tf.set_random_seed(1)\n",
    "auc_score=[]\n",
    "for i in range(1,6) :\n",
    "    train_d=pd.read_csv('C:/Desktop/Son/공모전/빅콘 2019/최종 데이터 및 코드/train_a'+str(i)+'.csv',engine = 'python')\n",
    "    valid_d = pd.read_csv(\"C:/Desktop/Son/공모전/빅콘 2019/최종 데이터 및 코드/valid_a\"+str(i)+\".csv\",engine='python')\n",
    "    train_y=train_d['dly']\n",
    "    train_x=train_d.drop(['dly','delay_time'],axis=1)\n",
    "    valid_y=valid_d['dly']\n",
    "    valid_x=valid_d.drop(['dly','delay_time'],axis=1)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor='val_loss', mode='min', save_best_only=True) # early stopping이 되기전 최적의 모델을 저장\n",
    "    my_callbacks = EarlyStopping(monitor='val_loss', patience=25, verbose=2, mode='min') # 과적합을 피하기 위해 early stopping 지정\n",
    "    neural_network = KerasClassifier(build_fn=create_network, batch_size=800, epochs=50, verbose=2,validation_data=(valid_x, valid_y),callbacks=[my_callbacks,mc]) # early stopping\n",
    "    nnet=neural_network.fit(train_x, train_y)\n",
    "    ynew = neural_network.predict_proba(valid_x)\n",
    "    real_y=np.array(valid_y)\n",
    "    pred_y=np.array(pd.DataFrame(ynew).loc[:,1])\n",
    "    auc_score.append(roc_auc_score(real_y, pred_y))\n",
    "    valid_1=pd.DataFrame(ynew)\n",
    "    valid_1.to_csv(\"valid_\"+i+\".csv\",mode='w')\n",
    "print(auc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
